{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#### MUST DELETE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths & import src functions\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder = os.path.join(project_root, 'src')\n",
    "sys.path.insert(0, src_folder)\n",
    "from modeling import *\n",
    "from stats_and_visualisations import *\n",
    "from s3_storage import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "X_train = from_s3(bucket='mimic-jamesi',\n",
    "                  filepath='data/acute_kidney_failure_X_train.npy')\n",
    "y_train = from_s3(bucket='mimic-jamesi',\n",
    "                  filepath='data/acute_kidney_failure_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgb(X_train, y_train, param_grid, runs, n_folds, early_stopping_rounds):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function enables random grid search hyperparameter tuning on the LightGBM\n",
    "    model. The output is a DataFrame containing the training and cross validation\n",
    "    AUC scores for each run, along with the associated hyperparameters.\n",
    "    \n",
    "    The parameters are as follows:\n",
    "        1. X_train - feature training set (np.array)\n",
    "        2. y_train - target variable for training set (np.array)\n",
    "        3. param_grid - dictionary containing the hyperparameters and associated\n",
    "           ranges from which the randomly selected hyperparameter values will be\n",
    "           chosen. E.g, for {'max_depth': [1,2,3]}, the 'max_depth' hyperparamater\n",
    "           will be randomly chosen from the values [1,2,3]\n",
    "        4. runs - the number of random iterations of hyperparameters that will be run\n",
    "           on the model\n",
    "        5. n_folds - the number of K folds in the training data that will be run to\n",
    "           find cross validation accuracy\n",
    "        6. early_stopping_rounds - how many iterations of the LightGBM should be run\n",
    "           without improvement in cross validation accuracy before each run stops    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Prepare the output dataframe\n",
    "    df_cols = list(param_grid.keys()) + ['params', 'training_score', 'valid_score']\n",
    "    runs_df = pd.DataFrame(columns = df_cols)\n",
    "    \n",
    "    run =0\n",
    "    while run < runs:\n",
    "        run += 1\n",
    "        \n",
    "        # Select the random parameters & train the model\n",
    "        random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "\n",
    "        train_score, valid_score = train_lgb(X_train=X_train,\n",
    "                                             y_train=y_train,\n",
    "                                             n_folds=n_folds,\n",
    "                                             params=random_params,\n",
    "                                             eval_metric='auc',\n",
    "                                             early_stopping_rounds=early_stopping_rounds)\n",
    "        \n",
    "        # Add the hyperparameters, training and cross validation scores into the output DF\n",
    "        temp_df = pd.DataFrame(columns=df_cols)\n",
    "        \n",
    "        for c in list(param_grid.keys()):\n",
    "            temp_df.loc[0, c] = random_params[c]\n",
    "\n",
    "        temp_df.loc[0, 'params'] = [random_params]\n",
    "        temp_df.loc[0, 'training_score'] = train_score\n",
    "        temp_df.loc[0, 'valid_score'] = valid_score\n",
    "\n",
    "        runs_df = runs_df.append(temp_df)\n",
    "\n",
    "        del temp_df, train_score, valid_score\n",
    "        \n",
    "    runs_df['training_score'] = runs_df['training_score'].astype(float)\n",
    "    runs_df['valid_score'] = runs_df['valid_score'].astype(float)\n",
    "    \n",
    "    return runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(X_train, y_train, n_folds, params, eval_metric, early_stopping_rounds):\n",
    "    \n",
    "    '''\n",
    "    Takes a single set of hyperparameters and runs LightGBM, using K-Fold\n",
    "    for cross validation scoring.\n",
    "    \n",
    "    Outputs the training and cross validation AUC score.\n",
    "    '''\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "    \n",
    "    # Empty array for validation predictions\n",
    "    valid_predictions = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    # List for recording training scores\n",
    "    train_scores = []\n",
    "        \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(X_train):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features  = X_train[train_indices]\n",
    "        train_labels = [x for i,x in enumerate(y_train) if i in train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features = X_train[valid_indices]\n",
    "        valid_labels = [x for i,x in enumerate(y_train) if i in valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric=eval_metric,\n",
    "                  eval_set = [(valid_features, valid_labels),\n",
    "                              (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'],\n",
    "                  early_stopping_rounds=early_stopping_rounds,\n",
    "                  verbose=0)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_it = model.best_iteration_\n",
    "        \n",
    "        # Record the validation predictions\n",
    "        valid_predictions[valid_indices] = model.predict_proba(valid_features,\n",
    "                                                               num_iteration=best_it)[:, 1]\n",
    "        \n",
    "        # Record the best training score\n",
    "        train_score = model.best_score_['train'][eval_metric]        \n",
    "        train_scores.append(train_score)\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(y_train, valid_predictions)\n",
    "\n",
    "    # Overall training score\n",
    "    train_auc = np.mean(train_scores)\n",
    "        \n",
    "    return train_auc, valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(10, 150)),\n",
    "    'learning_rate': list(np.linspace(0.001, 0.5)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_data_in_leaf': list(range(10, 250, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.001, 1)),\n",
    "    'subsample': list(np.linspace(0.5, 1)),\n",
    "    'is_unbalance': [True, False],\n",
    "    'min_split_gain': list(np.linspace(0.001, 1)),\n",
    "    'min_data_in_leaf': list(np.arange(1, 200, 3)),\n",
    "    'n_estimators': list(np.arange(100, 20100, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = tune_lgb(X_train, y_train, param_grid, runs=250, n_folds=5,\n",
    "                   early_stopping_rounds=100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters & CV score\n",
    "best_params=runs_df.loc[runs_df['valid_score'].max() ==\n",
    "                        runs_df['valid_score'], 'params'].values[0][0]\n",
    "print('Best CV Score: ', runs_df['valid_score'].max())\n",
    "\n",
    "# Visualise best CV score by run\n",
    "best_cv_by_run(runs_df, 'valid_score')\n",
    "\n",
    "# Visualise the scores by single hyperparameters\n",
    "plot_single_results(runs_df, 'training_score', 'valid_score', 'params')\n",
    "\n",
    "runs_df.sort_values(by='valid_score', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run on best parameters and save model\n",
    "final_run(X_train, y_train,\n",
    "          best_params=best_params,\n",
    "          classifier=lgb.LGBMClassifier,\n",
    "          model_name='light_gbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
