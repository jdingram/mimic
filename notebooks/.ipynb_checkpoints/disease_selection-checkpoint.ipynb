{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/James/anaconda3/envs/mimic/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Check virtual environment: should be: '/Users/James/anaconda3/envs/mimic/bin/python'\n",
    "print(sys.executable)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### MUST DELETE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths & import functions\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder = os.path.join(project_root, 'src')\n",
    "sys.path.insert(0, src_folder)\n",
    "from stats_and_visualisations import *\n",
    "from patient_selection import *\n",
    "from utilities import *\n",
    "from modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- OPTIONS\n",
    "optional_exclusions = ['first_diagnosis_only', 'exclude_newborns', 'exclude_deaths']\n",
    "match_on = ['age_adm_bucket', 'gender']\n",
    "profile_data = ['age_adm_bucket', 'gender']\n",
    "show_graphs = False\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_patients_and_select_chartevents(diagnosis_id, diagnosis_name,\n",
    "                                           test_size=0.33,\n",
    "                                           optional_exclusions=None,\n",
    "                                           profile_data=None,\n",
    "                                           match_on=False,\n",
    "                                           show_graphs=False):\n",
    "    \n",
    "    '''\n",
    "\n",
    "    Function that for a given dignosis idc9 code:\n",
    "        1) Finds patients who were diagnosed with the condition (target=1) and a 'base' group who were never diagnosed\n",
    "           with the condition (target=0)\n",
    "        2) Adds the final chart and lab events for each admission, and (optionally) additional patient demographic\n",
    "           data such as gender and age. It also optionally provides visualisations of the chart, lab and demographic\n",
    "           data so that comparisons can be seen between the subject and base groups\n",
    "        3) Finally, it splits the data into a training set and a test set, both of which are saved on AWS S3\n",
    "    \n",
    "    The arguments are as follows:\n",
    "        1) diagnosis_id: the icd9 code of the diagnosis that we wish to find patients for, with an appropriate base\n",
    "           group who never had the diagnosis.\n",
    "        2) diagnosis_name: the corresponding name for the diagnosis_id. Used to name the output training and test\n",
    "           sets, so can be in short form/ easy to understand language.\n",
    "        3) test_size: the proportion of total patients that should be placed in the test dataset (between 0 and 1).\n",
    "           The default is 0.33.\n",
    "        4) optional_exclusions: There are additional optional exlusions that can be applied to the subject and\n",
    "           base group. These should be passed as a list into the optional_exclusions argument. This argument can\n",
    "           be omitted if no exclusions are needed:\n",
    "              a) first_diagnosis_only - this means that only one admission per patient\n",
    "                 will be included in the output dataframes. In the subject dataframe,\n",
    "                 the first admission where they were diagnosed with the condition will\n",
    "                 be included (not necessarily their first admission overall, if they \n",
    "                 were not diagnosed on their first admission)\n",
    "              b) exclude_newborns - excludes all admissions with admission_type ==\n",
    "                 'NEWBORN'\n",
    "              c) exclude_deaths - excludes all admissions that resulted in the\n",
    "                 patient dying\n",
    "        5) profile_data: the patient demographic data that is required in the final datasets. Needs to be passed\n",
    "           as a list, eg ['gender', 'age_adm_bucket']. Must be a column in the admission_diagnosis_table dataset.\n",
    "        6) match_on: The subject and base groups can be matched on their patient demographic data with the match_on\n",
    "           argument. The match can take place on any demographic data in the input dataframe, and the chosen columns\n",
    "           for the match should be passed as a list, eg ['gender', 'ethnicity_simple'].\n",
    "           \n",
    "           The match works by randomly sampling the base group so the proportions in each demographic bucket match\n",
    "           the proportions in the subject group. For example, if the proportion of males to females in the\n",
    "           subject group is 60/40 whereas in the base group it is 50/50, then the base group will be randomly\n",
    "           sampled so that the male to female ratio is also 60/40.\n",
    "           \n",
    "           The match is taken on all combinations of matched columns together rather than separately. Eg, if 10% of\n",
    "           the sampled group is white female, then the base group will be sampled so that 10% are also white female,\n",
    "           rather than sampling ethnicity and gender separately. Therefore, it's recommended to only match on groups\n",
    "           where there are large volumes in each bucket, otherwise the base group could become quite small\n",
    "           \n",
    "        7) show_graphs: if True, graphs are output which show comparisons between the subject and base groups\n",
    "           for chart, lab and demographic data\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df = select_test_groups(diagnosis_id, optional_exclusions=optional_exclusions,\n",
    "                            match_on=match_on, show_graphs=show_graphs)\n",
    "                            \n",
    "    df = add_chart_data(df)\n",
    "\n",
    "    if profile_data:\n",
    "        df = add_profile_data(df, profile_data=profile_data)\n",
    "        non_chart_cols = ['subject_id', 'hadm_id', 'target'] +  profile_data\n",
    "    else:\n",
    "        non_chart_cols = ['subject_id', 'hadm_id', 'target']\n",
    "    \n",
    "    if show_graphs:\n",
    "        # Plot a KDE for all remaining cols\n",
    "        cols = [c for c in df.columns if c not in non_chart_cols]\n",
    "        for c in cols:\n",
    "            plot_KDE(df, 'target', 1, 0, c)\n",
    "            \n",
    "    # Create dummy variables for categorical variables so that ML models can be used\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Shuffle and reset index so that the subject and base groups are mixed together\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    # Take test and train splits\n",
    "    train, test = train_test_split(df, test_size=test_size, shuffle=True, random_state=8)\n",
    "    \n",
    "    print(\"--> Training set counts: \",\"\\n\",train.target.value_counts())\n",
    "    print(\"--> Test set counts: \",\"\\n\",test.target.value_counts())\n",
    "    \n",
    "    # Export to csv\n",
    "    to_s3(df=train, bucket='mimic-jamesi', filename='{}_train.csv'.format(diagnosis_name))\n",
    "    to_s3(df=test, bucket='mimic-jamesi', filename='{}_test.csv'.format(diagnosis_name))\n",
    "    \n",
    "    del df, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_test_groups(diagnosis,\n",
    "                       optional_exclusions=None,\n",
    "                       match_on=False,\n",
    "                       show_graphs=False):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    For a given diagnoses icd9 code, returns a single dataframe showing patients and admissions that either did or\n",
    "    didn't have the disgnosis (denoted by target == 1 or 0) \n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Find initial subject and base group for the given diagnosis\n",
    "    subject_adm, base_adm = get_diagnosis_groups(diagnosis, optional_exclusions=optional_exclusions)\n",
    "    \n",
    "    if match_on:\n",
    "        base_adm = take_match_control(subject_adm, base_adm, match_on=match_on)\n",
    "\n",
    "    # Combine into a single DF\n",
    "    subject_adm['target'] = 1\n",
    "    base_adm['target'] = 0\n",
    "    df = subject_adm.append(base_adm).reset_index(drop=True)\n",
    "\n",
    "    if show_graphs:\n",
    "        graph_comparisons(df = df, ids = 'hadm_id', group_col = 'target', group_a = 1, group_b = 0)\n",
    "\n",
    "    df['subject_id'] = df['subject_id'].astype(int)\n",
    "    df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "    \n",
    "    df = df[['subject_id', 'hadm_id', 'target']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_match_control(subject_adm, base_adm, match_on):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    For a given subject and base group, returns a new base group that is identical in proportions for\n",
    "    given variables compared to the subject group.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # === 1 === For the subject and base groups, calculate the proportion of patients in each combination of the\n",
    "    #           match_on variables. This is so the proportions can be compared, and ultimately the base group can\n",
    "    #           be sampled until it's proportions are equal to the subject proportions\n",
    "    \n",
    "    # Subjects\n",
    "    subject_segments = (subject_adm.groupby(match_on)\n",
    "                                   .agg({'hadm_id':'nunique'})\n",
    "                                   .rename(columns={'hadm_id':'subjects_n'})\n",
    "                                   .reset_index())\n",
    "    subject_segments['subjects_prop'] = subject_segments['subjects_n'] / subject_segments['subjects_n'].sum()\n",
    "\n",
    "    # Base\n",
    "    base_segments = (base_adm.groupby(match_on)\n",
    "                             .agg({'hadm_id':'nunique'})\n",
    "                             .rename(columns={'hadm_id':'base_n'})\n",
    "                             .reset_index())\n",
    "    base_segments['base_prop'] = base_segments['base_n'] / base_segments['base_n'].sum()\n",
    "\n",
    "    proportions_compare = pd.merge(subject_segments, base_segments, how='outer',\n",
    "                                   left_on=match_on, right_on=match_on)\n",
    "\n",
    "    # === 2 === Compare proportions: For each combination, the proportion % of the base and the subject group should\n",
    "    #           be compared. The goal is to find the combination where there is the lowest ratio of base group to\n",
    "    #           subject group. This is because this is the combination group that cannot be down sampled any further\n",
    "    #           if we want to maximise the size of the base group. Therefore, if we know the size of this combination\n",
    "    #           group we can use it as a basis for calculating the target size of all other combination groups\n",
    "    \n",
    "    proportions_compare['ratio'] = proportions_compare['base_prop'] / proportions_compare['subjects_prop']\n",
    "    lowest = proportions_compare[proportions_compare['ratio']==proportions_compare['ratio'].min()]\n",
    "    total_sample_size = math.floor(lowest['base_n'] / lowest['subjects_prop'])\n",
    "    proportions_compare['new_base_grp_size'] = ((total_sample_size * proportions_compare['subjects_prop'])\n",
    "                                                .apply(np.floor))\n",
    "\n",
    "    # === 3 === With the target group size known for each combination, loop through each combination and randomly\n",
    "    #           sample from the base group the desired number of admissions\n",
    "                                \n",
    "    base_adm_sampled = df_empty(columns=base_adm.columns.tolist(), dtypes=base_adm.dtypes.tolist())\n",
    "\n",
    "    for idx,row in proportions_compare.iterrows():\n",
    "        \n",
    "        tmp_base = base_adm.copy()\n",
    "        \n",
    "        n = int(row['new_base_grp_size'])\n",
    "        \n",
    "        for val in match_on:\n",
    "            tmp_base = tmp_base[tmp_base[val]==row[val]]\n",
    "                    \n",
    "        sample_df = tmp_base.sample(n=n, random_state=8)\n",
    "\n",
    "        base_adm_sampled = base_adm_sampled.append(sample_df)\n",
    "        \n",
    "        del sample_df, tmp_base\n",
    "\n",
    "    print('--> Original base group size: ', len(base_adm))\n",
    "    print('--> Sampled base group size: ', len(base_adm_sampled))\n",
    "    print('--> Subject group size: ', len(subject_adm))\n",
    "    \n",
    "    return base_adm_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  29491\n",
      "--> Sampled base group size:  22082\n",
      "--> Subject group size:  4806\n",
      "--> Training set counts:  \n",
      " 0    17650\n",
      "1     3860\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    4432\n",
      "1     946\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('53081', 'esophageal_reflux',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  31771\n",
      "--> Sampled base group size:  16586\n",
      "--> Subject group size:  2534\n",
      "--> Training set counts:  \n",
      " 0    13264\n",
      "1     2032\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    3322\n",
      "1     502\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('412', 'old_myocardial_infarction',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  32625\n",
      "--> Sampled base group size:  15281\n",
      "--> Subject group size:  1723\n",
      "--> Training set counts:  \n",
      " 0    12206\n",
      "1     1397\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    3075\n",
      "1     326\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('49390', 'asthma',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  32909\n",
      "--> Sampled base group size:  6406\n",
      "--> Subject group size:  1426\n",
      "--> Training set counts:  \n",
      " 0    5103\n",
      "1    1162\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    1303\n",
      "1     264\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('73300', 'osteoperosis',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  32803\n",
      "--> Sampled base group size:  14011\n",
      "--> Subject group size:  1526\n",
      "--> Training set counts:  \n",
      " 0    11202\n",
      "1     1227\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    2809\n",
      "1     299\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('2749', 'gout',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  18381\n",
      "--> Sampled base group size:  10287\n",
      "--> Subject group size:  15866\n",
      "--> Training set counts:  \n",
      " 1    12756\n",
      "0     8166\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 1    3110\n",
      "0    2121\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('4019', 'hypertension',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  27967\n",
      "--> Sampled base group size:  9479\n",
      "--> Subject group size:  6096\n",
      "--> Training set counts:  \n",
      " 0    7562\n",
      "1    4898\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    1917\n",
      "1    1198\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('5849', 'acute_kidney_failure',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  31739\n",
      "--> Sampled base group size:  14068\n",
      "--> Subject group size:  2235\n",
      "--> Training set counts:  \n",
      " 0    11248\n",
      "1     1794\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    2820\n",
      "1     441\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('99592', 'severe_sepsis',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  29337\n",
      "--> Sampled base group size:  23820\n",
      "--> Subject group size:  4596\n",
      "--> Training set counts:  \n",
      " 0    19085\n",
      "1     3647\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    4735\n",
      "1     949\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('51881', 'acute_respiratory_failure',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  29726\n",
      "--> Sampled base group size:  20400\n",
      "--> Subject group size:  4525\n",
      "--> Training set counts:  \n",
      " 0    16324\n",
      "1     3616\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    4076\n",
      "1     909\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('2859', 'anemia',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LogisticRegression(random_state=0,\n",
    "                             solver='lbfgs',\n",
    "                             class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict_proba(X_train)\n",
    "    test_predict = clf.predict_proba(X_test)\n",
    "\n",
    "    train_score = roc_auc_score(y_train, train_predict[:,1])\n",
    "    test_score = roc_auc_score(y_test, test_predict[:,1])\n",
    "\n",
    "    print('Logistic Train', train_score)\n",
    "    print('Logistic Test', test_score)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=0, \n",
    "                                 n_estimators=285,\n",
    "                                 max_features=14,\n",
    "                                 max_depth=61,\n",
    "                                 min_samples_split=96,\n",
    "                                 min_samples_leaf=140,\n",
    "                                 bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = rf.predict_proba(X_train)\n",
    "    test_predict = rf.predict_proba(X_test)\n",
    "\n",
    "    train_score = roc_auc_score(y_train, train_predict[:,1])\n",
    "    test_score = roc_auc_score(y_test, test_predict[:,1])\n",
    "\n",
    "    print('RF Train', train_score)\n",
    "    print('RF Test', test_score)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======  depression  ======\n",
      "Logistic Train 0.6603524232064311\n",
      "Logistic Test 0.6252817322002036\n",
      "RF Train 0.7533173891537548\n",
      "RF Test 0.6038333692331792\n",
      "\n",
      "======  anemia  ======\n",
      "Logistic Train 0.6467449946790979\n",
      "Logistic Test 0.6301653349829586\n",
      "RF Train 0.7324899914589084\n",
      "RF Test 0.6414711515312472\n",
      "\n",
      "======  esophageal_reflux  ======\n",
      "Logistic Train 0.6051604382861924\n",
      "Logistic Test 0.6041167780355821\n",
      "RF Train 0.7386516975150083\n",
      "RF Test 0.6095615159020309\n",
      "\n",
      "======  old_myocardial_infarction  ======\n",
      "Logistic Train 0.6088610207132206\n",
      "Logistic Test 0.6017864124477406\n",
      "RF Train 0.7493567189147347\n",
      "RF Test 0.6057842681051832\n",
      "\n",
      "======  asthma  ======\n",
      "Logistic Train 0.6063539576098265\n",
      "Logistic Test 0.5774741882388149\n",
      "RF Train 0.7824330911572762\n",
      "RF Test 0.574566312534291\n",
      "\n",
      "======  osteoperosis  ======\n",
      "Logistic Train 0.6803330732858367\n",
      "Logistic Test 0.6161393288216006\n",
      "RF Train 0.7358559121005732\n",
      "RF Test 0.6267151561664225\n",
      "\n",
      "======  gout  ======\n",
      "Logistic Train 0.7029533380274537\n",
      "Logistic Test 0.704402118846374\n",
      "RF Train 0.7766084674307927\n",
      "RF Test 0.6985882691920737\n",
      "\n",
      "======  hypertension  ======\n",
      "Logistic Train 0.645573712815614\n",
      "Logistic Test 0.6435809566257498\n",
      "RF Train 0.7121743461001713\n",
      "RF Test 0.6581957943153065\n",
      "\n",
      "======  acute_kidney_failure  ======\n",
      "Logistic Train 0.8458430857517693\n",
      "Logistic Test 0.8358002774577347\n",
      "RF Train 0.881995255445956\n",
      "RF Test 0.861229984246044\n",
      "\n",
      "======  severe_sepsis  ======\n",
      "Logistic Train 0.8792975557849702\n",
      "Logistic Test 0.8573085025972563\n",
      "RF Train 0.9032031558490368\n",
      "RF Test 0.8775252890754411\n",
      "\n",
      "======  acute_respiratory_failure  ======\n",
      "Logistic Train 0.766406064853962\n",
      "Logistic Test 0.7448526376344576\n",
      "RF Train 0.8607616453860928\n",
      "RF Test 0.8282158844468084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conditions = ['depression',\n",
    "              'anemia',\n",
    "              'esophageal_reflux',\n",
    "              'old_myocardial_infarction',\n",
    "              'asthma',\n",
    "              'osteoperosis',\n",
    "              'gout',\n",
    "              'hypertension',\n",
    "              'acute_kidney_failure',\n",
    "              'severe_sepsis',\n",
    "              'acute_respiratory_failure']\n",
    "\n",
    "output_df = pd.DataFrame(columns=['condition', 'model', 'train', 'test'])\n",
    "\n",
    "for c in conditions:\n",
    "    \n",
    "    print('======  {}  ======'.format(c))\n",
    "    \n",
    "    train = from_s3(bucket='mimic-jamesi',\n",
    "               filename='{}_train.csv'.format(c),\n",
    "               index_col=0)\n",
    "\n",
    "    test = from_s3(bucket='mimic-jamesi',\n",
    "                   filename='{}_test.csv'.format(c),\n",
    "                   index_col=0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, f = final_cleaning(ids = ['subject_id', 'hadm_id'],\n",
    "                                                  target = 'target',\n",
    "                                                  train = train, test=test)\n",
    "    \n",
    "    logistic_train, logistic_test = train_logistic(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    rf_train, rf_test = train_rf(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    tmp_df = pd.DataFrame(columns=['condition', 'model', 'train', 'test'])\n",
    "    \n",
    "    tmp_df.loc[0, 'condition'] = c\n",
    "    tmp_df.loc[0, 'model'] = 'logistic'\n",
    "    tmp_df.loc[0, 'train'] = logistic_train\n",
    "    tmp_df.loc[0, 'test'] = logistic_test\n",
    "    \n",
    "    tmp_df.loc[1, 'condition'] = c\n",
    "    tmp_df.loc[1, 'model'] = 'rf'\n",
    "    tmp_df.loc[1, 'train'] = rf_train\n",
    "    tmp_df.loc[1, 'test'] = rf_test\n",
    "    \n",
    "    output_df = output_df.append(tmp_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_sepsis</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.903203</td>\n",
       "      <td>0.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acute_kidney_failure</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.881995</td>\n",
       "      <td>0.86123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severe_sepsis</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.879298</td>\n",
       "      <td>0.857309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acute_kidney_failure</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.845843</td>\n",
       "      <td>0.8358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acute_respiratory_failure</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.860762</td>\n",
       "      <td>0.828216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acute_respiratory_failure</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.766406</td>\n",
       "      <td>0.744853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gout</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.702953</td>\n",
       "      <td>0.704402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gout</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.776608</td>\n",
       "      <td>0.698588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.712174</td>\n",
       "      <td>0.658196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hypertension</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.645574</td>\n",
       "      <td>0.643581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anemia</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.73249</td>\n",
       "      <td>0.641471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anemia</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.646745</td>\n",
       "      <td>0.630165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osteoperosis</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.735856</td>\n",
       "      <td>0.626715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depression</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.660352</td>\n",
       "      <td>0.625282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>osteoperosis</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.680333</td>\n",
       "      <td>0.616139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esophageal_reflux</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.738652</td>\n",
       "      <td>0.609562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>old_myocardial_infarction</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.605784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esophageal_reflux</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.60516</td>\n",
       "      <td>0.604117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.753317</td>\n",
       "      <td>0.603833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old_myocardial_infarction</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.608861</td>\n",
       "      <td>0.601786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asthma</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.606354</td>\n",
       "      <td>0.577474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asthma</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.782433</td>\n",
       "      <td>0.574566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   condition     model     train      test\n",
       "1              severe_sepsis        rf  0.903203  0.877525\n",
       "1       acute_kidney_failure        rf  0.881995   0.86123\n",
       "0              severe_sepsis  logistic  0.879298  0.857309\n",
       "0       acute_kidney_failure  logistic  0.845843    0.8358\n",
       "1  acute_respiratory_failure        rf  0.860762  0.828216\n",
       "0  acute_respiratory_failure  logistic  0.766406  0.744853\n",
       "0                       gout  logistic  0.702953  0.704402\n",
       "1                       gout        rf  0.776608  0.698588\n",
       "1               hypertension        rf  0.712174  0.658196\n",
       "0               hypertension  logistic  0.645574  0.643581\n",
       "1                     anemia        rf   0.73249  0.641471\n",
       "0                     anemia  logistic  0.646745  0.630165\n",
       "1               osteoperosis        rf  0.735856  0.626715\n",
       "0                 depression  logistic  0.660352  0.625282\n",
       "0               osteoperosis  logistic  0.680333  0.616139\n",
       "1          esophageal_reflux        rf  0.738652  0.609562\n",
       "1  old_myocardial_infarction        rf  0.749357  0.605784\n",
       "0          esophageal_reflux  logistic   0.60516  0.604117\n",
       "1                 depression        rf  0.753317  0.603833\n",
       "0  old_myocardial_infarction  logistic  0.608861  0.601786\n",
       "0                     asthma  logistic  0.606354  0.577474\n",
       "1                     asthma        rf  0.782433  0.574566"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.sort_values(by='test', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mimic]",
   "language": "python",
   "name": "conda-env-mimic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
