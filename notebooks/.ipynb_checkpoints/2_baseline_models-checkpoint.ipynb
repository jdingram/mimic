{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/James/anaconda3/envs/mimic/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check virtual environment: should be: '/Users/James/anaconda3/envs/mimic/bin/python'\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder = os.path.join(project_root, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import src functions\n",
    "sys.path.insert(0, src_folder)\n",
    "from modeling import *\n",
    "from stats_and_visualisations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- PARAMETERS\n",
    "iterations_per_model = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Importing done\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "train = pd.read_csv(os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'data', 'acute_respiratory_failure_train.csv')),index_col=0)\n",
    "print('--> Importing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Cleaning done\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = final_cleaning(ids = ['subject_id', 'hadm_id'], target = 'target', train = train)\n",
    "print('--> Cleaning done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(model, random_grid, scoring, cv, n_iter, X_train, y_train):\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    m = model\n",
    "    print('--> Model defined')\n",
    "\n",
    "    random_search_model = RandomizedSearchCV(estimator = m, scoring=scoring,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = n_iter, cv = cv, verbose=0,\n",
    "                                   random_state=8, n_jobs = -1,\n",
    "                                   return_train_score=True)\n",
    "    print('--> Random search defined')\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search_model.fit(X_train, y_train)\n",
    "    print('--> Fitting done')\n",
    "\n",
    "    # Print the best CV score\n",
    "    print('--> Best CV Score: ', random_search_model.best_score_)\n",
    "    \n",
    "    return random_search_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_results(random_grid, random_search_model, training_score, cv_score, fit_time):\n",
    "    \n",
    "    # Clean the CV results df, keeping only columns that are needed\n",
    "    keep_cols = ['param_{}'.format(param) for param in random_grid.keys()]\n",
    "    keep_cols = keep_cols + [training_score, cv_score, fit_time]\n",
    "    results = pd.DataFrame(random_search_model.cv_results_)[keep_cols]\n",
    "\n",
    "    # Visualise best CV score by run\n",
    "    best_cv_by_run(results, cv_score)\n",
    "\n",
    "    # Visualise the scores by single hyperparameters\n",
    "    plot_single_results(results, training_score, cv_score, fit_time)\n",
    "\n",
    "    # Visualise the scores by double hyperparameters\n",
    "    plot_double_results(results, [training_score, cv_score, fit_time])\n",
    "\n",
    "    results.sort_values(by=cv_score, ascending=False, inplace=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Grid defined\n"
     ]
    }
   ],
   "source": [
    "C = list(np.arange(0.01, 5, 0.01))\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Create the random grid\n",
    "logistic_random_grid = {'C': C,\n",
    "                        'solver': solver}\n",
    "\n",
    "print('--> Grid defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Model defined\n",
      "--> Random search defined\n"
     ]
    }
   ],
   "source": [
    "# Run the random search model\n",
    "logistic_random_search_model = run_random_search(model=LogisticRegression(class_weight='balanced'),\n",
    "                                        random_grid=logistic_random_grid,\n",
    "                                        scoring='roc_auc', cv=4, n_iter=iterations_per_model, \n",
    "                                        X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results to find optimal hyperparameters\n",
    "logistic_results = visualise_results(random_grid=logistic_random_grid, random_search_model=logistic_random_search_model,\n",
    "                            training_score='mean_train_score', cv_score='mean_test_score', fit_time='mean_fit_time')\n",
    "logistic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "n_estimators = list(np.arange(20, 3000, 5))\n",
    "max_features = list(np.arange(2, X_train.shape[1]))\n",
    "max_depth = list(np.arange(1, 100))\n",
    "max_depth.append(None)\n",
    "min_samples_split = list(np.arange(2, 250))\n",
    "min_samples_leaf = list(np.arange(1, 250))\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "rf_random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "print('--> Grid defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the random search model\n",
    "rf_random_search_model = run_random_search(model=RandomForestRegressor(), random_grid=rf_random_grid,\n",
    "                                        scoring='roc_auc', cv=4, n_iter=iterations_per_model, \n",
    "                                        X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results to find optimal hyperparameters\n",
    "rf_results = visualise_results(random_grid=rf_random_grid, random_search_model=rf_random_search_model,\n",
    "                            training_score='mean_train_score', cv_score='mean_test_score', fit_time='mean_fit_time')\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "C=list(np.logspace(-4, 5, 10))\n",
    "gamma=list(np.logspace(-7, 4, 12))\n",
    "kernel=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degree=[1,2,3]\n",
    "\n",
    "# Create the random grid\n",
    "svm_random_grid = {'C': C,\n",
    "                   'kernel': kernel,\n",
    "                   'degree': degree,\n",
    "                   'gamma': gamma}\n",
    "\n",
    "print('--> Grid defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the random search model\n",
    "svm_random_search_model = run_random_search(model=SVC(class_weight='balanced'),\n",
    "                                        random_grid=svm_random_grid,\n",
    "                                        scoring='roc_auc', cv=4, n_iter=iterations_per_model, \n",
    "                                        X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results to find optimal hyperparameters\n",
    "svm_results = visualise_results(random_grid=svm_random_grid, random_search_model=svm_random_search_model,\n",
    "                            training_score='mean_train_score', cv_score='mean_test_score', fit_time='mean_fit_time')\n",
    "svm_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mimic]",
   "language": "python",
   "name": "conda-env-mimic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
