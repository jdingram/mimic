{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/James/anaconda3/envs/mimic/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some display options\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/James/anaconda3/envs/mimic/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check virtual environment: should be: '/Users/James/anaconda3/envs/mimic/bin/python'\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder = os.path.join(project_root, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import src functions\n",
    "sys.path.insert(0, src_folder)\n",
    "from modeling import *\n",
    "from stats_and_visualisations import *\n",
    "from s3_storage import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Importing done\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "train = from_s3(bucket='mimic-jamesi',\n",
    "               filename='acute_kidney_failure_train.csv',\n",
    "               index_col=0)\n",
    "\n",
    "test = from_s3(bucket='mimic-jamesi',\n",
    "               filename='acute_kidney_failure_test.csv',\n",
    "               index_col=0)\n",
    "print('--> Importing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Cleaning done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names = final_cleaning(ids = ['subject_id', 'hadm_id'],\n",
    "                                                                  target = 'target',\n",
    "                                                                  train = train, test=test)\n",
    "print('--> Cleaning done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(X_train, y_train, n_folds, params, eval_metric, early_stopping_rounds):\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    print('LGB starting')\n",
    "        \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(X_train):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features  = X_train[train_indices]\n",
    "        train_labels = [x for i,x in enumerate(y_train) if i in train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features = X_train[valid_indices]\n",
    "        valid_labels = [x for i,x in enumerate(y_train) if i in valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = eval_metric,\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], early_stopping_rounds = early_stopping_rounds, verbose=500)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid'][eval_metric]\n",
    "        train_score = model.best_score_['train'][eval_metric]\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(y_train, out_of_fold)\n",
    "\n",
    "    # Overall training score\n",
    "    train_auc = np.mean(train_scores)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(train_auc)\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores})\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "    return metrics, train_auc, valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(10, 150)),\n",
    "    'learning_rate': list(np.linspace(0.001, 0.5)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_data_in_leaf': list(range(10, 250, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.001, 1)),\n",
    "    'subsample': list(np.linspace(0.5, 1)),\n",
    "    'is_unbalance': [True, False],\n",
    "    'min_split_gain': list(np.linspace(0.001, 1)),\n",
    "    'min_data_in_leaf': list(np.arange(1, 200, 3)),\n",
    "    'n_estimators': list(np.arange(100, 20100, 1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgb(X_train, y_train, param_grid, runs):\n",
    "    \n",
    "    ## -- Create output dataframe showing scores and associated hyperparameters\n",
    "    df_cols = list(param_grid.keys())\n",
    "    df_cols = df_cols + ['params', 'training_score', 'valid_score']\n",
    "\n",
    "    runs_df = pd.DataFrame(columns=df_cols)\n",
    "    total_runs = runs\n",
    "    run =0\n",
    "\n",
    "    while run < total_runs:\n",
    "\n",
    "        run += 1\n",
    "\n",
    "        # Select the random parameters\n",
    "        random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "\n",
    "        print('=========')\n",
    "        print('RUN IS ' + str(run))\n",
    "        print('=========')\n",
    "\n",
    "        metrics, train_score, valid_score= train_lgb(X_train=X_train,\n",
    "                                                      y_train=y_train,\n",
    "                                                      n_folds = 4,\n",
    "                                                      params = random_params,\n",
    "                                                      eval_metric = 'auc',\n",
    "                                                      early_stopping_rounds = 250)\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=df_cols)\n",
    "\n",
    "        for c in list(param_grid.keys()):\n",
    "            temp_df.loc[0, c] = random_params[c]\n",
    "\n",
    "        temp_df.loc[0, 'params'] = [random_params]\n",
    "        temp_df.loc[0, 'training_score'] = train_score\n",
    "        temp_df.loc[0, 'valid_score'] = valid_score\n",
    "\n",
    "        runs_df = runs_df.append(temp_df)\n",
    "\n",
    "        del temp_df, train_score, valid_score\n",
    "        \n",
    "    return runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "RUN IS 1\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid's binary_logloss: 0.49262\tvalid's auc: 0.839585\ttrain's binary_logloss: 0.334465\ttrain's auc: 0.970375\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid's binary_logloss: 0.509497\tvalid's auc: 0.824184\ttrain's binary_logloss: 0.376151\ttrain's auc: 0.95331\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid's binary_logloss: 0.495745\tvalid's auc: 0.835994\ttrain's binary_logloss: 0.335082\ttrain's auc: 0.968413\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid's binary_logloss: 0.510676\tvalid's auc: 0.825533\ttrain's binary_logloss: 0.33757\ttrain's auc: 0.967749\n",
      "      fold     train     valid\n",
      "0        0  0.970375  0.839585\n",
      "1        1  0.953310  0.824184\n",
      "2        2  0.968413  0.835994\n",
      "3        3  0.967749  0.825533\n",
      "4  overall  0.964962  0.831029\n",
      "=========\n",
      "RUN IS 2\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.490099\tvalid's auc: 0.83825\ttrain's binary_logloss: 0.171976\ttrain's auc: 0.999156\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid's binary_logloss: 0.489238\tvalid's auc: 0.83757\ttrain's binary_logloss: 0.203957\ttrain's auc: 0.997604\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.506068\tvalid's auc: 0.824854\ttrain's binary_logloss: 0.171375\ttrain's auc: 0.999162\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid's binary_logloss: 0.49886\tvalid's auc: 0.825492\ttrain's binary_logloss: 0.255961\ttrain's auc: 0.990627\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.485412\tvalid's auc: 0.834602\ttrain's binary_logloss: 0.17582\ttrain's auc: 0.998917\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid's binary_logloss: 0.483329\tvalid's auc: 0.83409\ttrain's binary_logloss: 0.248978\ttrain's auc: 0.99213\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.506587\tvalid's auc: 0.823991\ttrain's binary_logloss: 0.170349\ttrain's auc: 0.999067\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid's binary_logloss: 0.496585\tvalid's auc: 0.826607\ttrain's binary_logloss: 0.250705\ttrain's auc: 0.991522\n",
      "      fold     train     valid\n",
      "0        0  0.997604  0.837570\n",
      "1        1  0.990627  0.825492\n",
      "2        2  0.992130  0.834090\n",
      "3        3  0.991522  0.826607\n",
      "4  overall  0.992971  0.830845\n",
      "=========\n",
      "RUN IS 3\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid's binary_logloss: 0.526671\tvalid's auc: 0.816308\ttrain's binary_logloss: 0.478328\ttrain's auc: 0.859756\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's binary_logloss: 0.530912\tvalid's auc: 0.807656\ttrain's binary_logloss: 0.481041\ttrain's auc: 0.855721\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's binary_logloss: 0.529533\tvalid's auc: 0.815378\ttrain's binary_logloss: 0.466321\ttrain's auc: 0.864859\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's binary_logloss: 0.540912\tvalid's auc: 0.807222\ttrain's binary_logloss: 0.488774\ttrain's auc: 0.851698\n",
      "      fold     train     valid\n",
      "0        0  0.859756  0.816308\n",
      "1        1  0.855721  0.807656\n",
      "2        2  0.864859  0.815378\n",
      "3        3  0.851698  0.807222\n",
      "4  overall  0.858009  0.811406\n",
      "=========\n",
      "RUN IS 4\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's binary_logloss: 0.514676\tvalid's auc: 0.820144\ttrain's binary_logloss: 0.39563\ttrain's auc: 0.919112\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's binary_logloss: 0.534779\tvalid's auc: 0.80089\ttrain's binary_logloss: 0.413978\ttrain's auc: 0.906336\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid's binary_logloss: 0.528816\tvalid's auc: 0.81027\ttrain's binary_logloss: 0.385102\ttrain's auc: 0.923895\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's binary_logloss: 0.538447\tvalid's auc: 0.803683\ttrain's binary_logloss: 0.396878\ttrain's auc: 0.916808\n",
      "      fold     train     valid\n",
      "0        0  0.919112  0.820144\n",
      "1        1  0.906336  0.800890\n",
      "2        2  0.923895  0.810270\n",
      "3        3  0.916808  0.803683\n",
      "4  overall  0.916538  0.808583\n",
      "=========\n",
      "RUN IS 5\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid's binary_logloss: 0.484075\tvalid's auc: 0.840986\ttrain's binary_logloss: 0.272131\ttrain's auc: 0.982867\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid's binary_logloss: 0.502425\tvalid's auc: 0.823142\ttrain's binary_logloss: 0.268408\ttrain's auc: 0.983393\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid's binary_logloss: 0.481383\tvalid's auc: 0.835531\ttrain's binary_logloss: 0.270798\ttrain's auc: 0.982902\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid's binary_logloss: 0.506101\tvalid's auc: 0.821748\ttrain's binary_logloss: 0.261339\ttrain's auc: 0.984526\n",
      "      fold     train     valid\n",
      "0        0  0.982867  0.840986\n",
      "1        1  0.983393  0.823142\n",
      "2        2  0.982902  0.835531\n",
      "3        3  0.984526  0.821748\n",
      "4  overall  0.983422  0.830866\n",
      "=========\n",
      "RUN IS 6\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid's binary_logloss: 0.510717\tvalid's auc: 0.828947\ttrain's binary_logloss: 0.443074\ttrain's auc: 0.878289\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid's binary_logloss: 0.51478\tvalid's auc: 0.819436\ttrain's binary_logloss: 0.466428\ttrain's auc: 0.862975\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's binary_logloss: 0.518296\tvalid's auc: 0.82046\ttrain's binary_logloss: 0.467639\ttrain's auc: 0.861491\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid's binary_logloss: 0.533279\tvalid's auc: 0.813869\ttrain's binary_logloss: 0.48161\ttrain's auc: 0.855157\n",
      "      fold     train     valid\n",
      "0        0  0.878289  0.828947\n",
      "1        1  0.862975  0.819436\n",
      "2        2  0.861491  0.820460\n",
      "3        3  0.855157  0.813869\n",
      "4  overall  0.864478  0.820530\n",
      "=========\n",
      "RUN IS 7\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid's binary_logloss: 0.506582\tvalid's auc: 0.830605\ttrain's binary_logloss: 0.128927\ttrain's auc: 0.999763\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid's binary_logloss: 0.52138\tvalid's auc: 0.817792\ttrain's binary_logloss: 0.135159\ttrain's auc: 0.999757\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid's binary_logloss: 0.498885\tvalid's auc: 0.828549\ttrain's binary_logloss: 0.133606\ttrain's auc: 0.99981\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid's binary_logloss: 0.512251\tvalid's auc: 0.81414\ttrain's binary_logloss: 0.284736\ttrain's auc: 0.978896\n",
      "      fold     train     valid\n",
      "0        0  0.999763  0.830605\n",
      "1        1  0.999757  0.817792\n",
      "2        2  0.999810  0.828549\n",
      "3        3  0.978896  0.814140\n",
      "4  overall  0.994557  0.815258\n",
      "=========\n",
      "RUN IS 8\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.488274\tvalid's auc: 0.838588\ttrain's binary_logloss: 0.248317\ttrain's auc: 0.992336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[595]\tvalid's binary_logloss: 0.487671\tvalid's auc: 0.838717\ttrain's binary_logloss: 0.235707\ttrain's auc: 0.995413\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.502645\tvalid's auc: 0.825485\ttrain's binary_logloss: 0.246349\ttrain's auc: 0.992224\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid's binary_logloss: 0.50148\tvalid's auc: 0.82611\ttrain's binary_logloss: 0.261931\ttrain's auc: 0.98875\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.490283\tvalid's auc: 0.836128\ttrain's binary_logloss: 0.252358\ttrain's auc: 0.991365\n",
      "Early stopping, best iteration is:\n",
      "[707]\tvalid's binary_logloss: 0.487901\tvalid's auc: 0.837381\ttrain's binary_logloss: 0.212971\ttrain's auc: 0.9976\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.507467\tvalid's auc: 0.825518\ttrain's binary_logloss: 0.24553\ttrain's auc: 0.992417\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid's binary_logloss: 0.504996\tvalid's auc: 0.827461\ttrain's binary_logloss: 0.292967\ttrain's auc: 0.980778\n",
      "      fold     train     valid\n",
      "0        0  0.995413  0.838717\n",
      "1        1  0.988750  0.826110\n",
      "2        2  0.997600  0.837381\n",
      "3        3  0.980778  0.827461\n",
      "4  overall  0.990635  0.832303\n",
      "=========\n",
      "RUN IS 9\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's binary_logloss: 0.502863\tvalid's auc: 0.830705\ttrain's binary_logloss: 0.416567\ttrain's auc: 0.901651\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's binary_logloss: 0.525416\tvalid's auc: 0.808581\ttrain's binary_logloss: 0.418566\ttrain's auc: 0.900606\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's binary_logloss: 0.510559\tvalid's auc: 0.824565\ttrain's binary_logloss: 0.422728\ttrain's auc: 0.897978\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's binary_logloss: 0.527603\tvalid's auc: 0.813888\ttrain's binary_logloss: 0.415736\ttrain's auc: 0.901397\n",
      "      fold     train     valid\n",
      "0        0  0.901651  0.830705\n",
      "1        1  0.900606  0.808581\n",
      "2        2  0.897978  0.824565\n",
      "3        3  0.901397  0.813888\n",
      "4  overall  0.900408  0.819453\n",
      "=========\n",
      "RUN IS 10\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's binary_logloss: 0.510888\tvalid's auc: 0.826234\ttrain's binary_logloss: 0.448567\ttrain's auc: 0.880907\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's binary_logloss: 0.512572\tvalid's auc: 0.819499\ttrain's binary_logloss: 0.382346\ttrain's auc: 0.921254\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's binary_logloss: 0.51888\tvalid's auc: 0.81996\ttrain's binary_logloss: 0.447168\ttrain's auc: 0.881199\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's binary_logloss: 0.516269\tvalid's auc: 0.823127\ttrain's binary_logloss: 0.417652\ttrain's auc: 0.900468\n",
      "      fold     train     valid\n",
      "0        0  0.880907  0.826234\n",
      "1        1  0.921254  0.819499\n",
      "2        2  0.881199  0.819960\n",
      "3        3  0.900468  0.823127\n",
      "4  overall  0.895957  0.821649\n",
      "=========\n",
      "RUN IS 11\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's binary_logloss: 0.541153\tvalid's auc: 0.806169\ttrain's binary_logloss: 0.511704\ttrain's auc: 0.831781\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's binary_logloss: 0.548078\tvalid's auc: 0.79459\ttrain's binary_logloss: 0.512018\ttrain's auc: 0.832525\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's binary_logloss: 0.53736\tvalid's auc: 0.808571\ttrain's binary_logloss: 0.496571\ttrain's auc: 0.841785\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's binary_logloss: 0.554322\tvalid's auc: 0.797372\ttrain's binary_logloss: 0.499736\ttrain's auc: 0.839057\n",
      "      fold     train     valid\n",
      "0        0  0.831781  0.806169\n",
      "1        1  0.832525  0.794590\n",
      "2        2  0.841785  0.808571\n",
      "3        3  0.839057  0.797372\n",
      "4  overall  0.836287  0.801716\n",
      "=========\n",
      "RUN IS 12\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.596057\tvalid's auc: 0.804577\ttrain's binary_logloss: 0.587193\ttrain's auc: 0.826424\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid's binary_logloss: 0.624353\tvalid's auc: 0.807593\ttrain's binary_logloss: 0.619135\ttrain's auc: 0.823732\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.599711\tvalid's auc: 0.790222\ttrain's binary_logloss: 0.583658\ttrain's auc: 0.829056\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid's binary_logloss: 0.624401\tvalid's auc: 0.793166\ttrain's binary_logloss: 0.614741\ttrain's auc: 0.827839\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.595888\tvalid's auc: 0.80643\ttrain's binary_logloss: 0.588191\ttrain's auc: 0.824579\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid's binary_logloss: 0.621978\tvalid's auc: 0.808614\ttrain's binary_logloss: 0.61817\ttrain's auc: 0.823134\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.602879\tvalid's auc: 0.78719\ttrain's binary_logloss: 0.584464\ttrain's auc: 0.828992\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid's binary_logloss: 0.628163\tvalid's auc: 0.792696\ttrain's binary_logloss: 0.618807\ttrain's auc: 0.826849\n",
      "      fold     train     valid\n",
      "0        0  0.823732  0.807593\n",
      "1        1  0.827839  0.793166\n",
      "2        2  0.823134  0.808614\n",
      "3        3  0.826849  0.792696\n",
      "4  overall  0.825389  0.798609\n",
      "=========\n",
      "RUN IS 13\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid's binary_logloss: 0.496962\tvalid's auc: 0.833231\ttrain's binary_logloss: 0.260537\ttrain's auc: 0.981522\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid's binary_logloss: 0.514892\tvalid's auc: 0.817856\ttrain's binary_logloss: 0.259896\ttrain's auc: 0.981253\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid's binary_logloss: 0.484789\tvalid's auc: 0.83514\ttrain's binary_logloss: 0.265281\ttrain's auc: 0.979993\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's binary_logloss: 0.506653\tvalid's auc: 0.818775\ttrain's binary_logloss: 0.381776\ttrain's auc: 0.917682\n",
      "      fold     train     valid\n",
      "0        0  0.981522  0.833231\n",
      "1        1  0.981253  0.817856\n",
      "2        2  0.979993  0.835140\n",
      "3        3  0.917682  0.818775\n",
      "4  overall  0.965113  0.821860\n",
      "=========\n",
      "RUN IS 14\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid's binary_logloss: 0.494736\tvalid's auc: 0.833227\ttrain's binary_logloss: 0.222728\ttrain's auc: 0.995409\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid's binary_logloss: 0.508991\tvalid's auc: 0.818007\ttrain's binary_logloss: 0.235559\ttrain's auc: 0.993843\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.508759\tvalid's auc: 0.82584\ttrain's binary_logloss: 0.105826\ttrain's auc: 0.99989\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid's binary_logloss: 0.490732\tvalid's auc: 0.830175\ttrain's binary_logloss: 0.18748\ttrain's auc: 0.997841\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid's binary_logloss: 0.50631\tvalid's auc: 0.820766\ttrain's binary_logloss: 0.250886\ttrain's auc: 0.990597\n",
      "      fold     train     valid\n",
      "0        0  0.995409  0.833227\n",
      "1        1  0.993843  0.818007\n",
      "2        2  0.997841  0.830175\n",
      "3        3  0.990597  0.820766\n",
      "4  overall  0.994423  0.825957\n",
      "=========\n",
      "RUN IS 15\n",
      "=========\n",
      "LGB starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.51798\tvalid's auc: 0.814983\ttrain's binary_logloss: 0.419385\ttrain's auc: 0.888002\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid's binary_logloss: 0.516999\tvalid's auc: 0.815547\ttrain's binary_logloss: 0.424027\ttrain's auc: 0.885307\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.52553\tvalid's auc: 0.806714\ttrain's binary_logloss: 0.418142\ttrain's auc: 0.888231\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid's binary_logloss: 0.523543\tvalid's auc: 0.807589\ttrain's binary_logloss: 0.427094\ttrain's auc: 0.883296\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.503286\tvalid's auc: 0.822028\ttrain's binary_logloss: 0.424128\ttrain's auc: 0.885631\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid's binary_logloss: 0.501577\tvalid's auc: 0.822294\ttrain's binary_logloss: 0.434379\ttrain's auc: 0.879684\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid's binary_logloss: 0.525316\tvalid's auc: 0.807538\ttrain's binary_logloss: 0.43903\ttrain's auc: 0.876235\n",
      "      fold     train     valid\n",
      "0        0  0.885307  0.815547\n",
      "1        1  0.883296  0.807589\n",
      "2        2  0.879684  0.822294\n",
      "3        3  0.876235  0.807538\n",
      "4  overall  0.881130  0.812516\n",
      "=========\n",
      "RUN IS 16\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid's binary_logloss: 0.513232\tvalid's auc: 0.827388\ttrain's binary_logloss: 0.480829\ttrain's auc: 0.854759\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid's binary_logloss: 0.527347\tvalid's auc: 0.811086\ttrain's binary_logloss: 0.486433\ttrain's auc: 0.851552\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's binary_logloss: 0.517741\tvalid's auc: 0.824161\ttrain's binary_logloss: 0.466615\ttrain's auc: 0.86212\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid's binary_logloss: 0.541218\tvalid's auc: 0.805305\ttrain's binary_logloss: 0.470513\ttrain's auc: 0.86213\n",
      "      fold     train     valid\n",
      "0        0  0.854759  0.827388\n",
      "1        1  0.851552  0.811086\n",
      "2        2  0.862120  0.824161\n",
      "3        3  0.862130  0.805305\n",
      "4  overall  0.857640  0.816908\n",
      "=========\n",
      "RUN IS 17\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid's binary_logloss: 0.496922\tvalid's auc: 0.836515\ttrain's binary_logloss: 0.401607\ttrain's auc: 0.918791\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid's binary_logloss: 0.505289\tvalid's auc: 0.824219\ttrain's binary_logloss: 0.340522\ttrain's auc: 0.949656\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid's binary_logloss: 0.495903\tvalid's auc: 0.837162\ttrain's binary_logloss: 0.388162\ttrain's auc: 0.925183\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid's binary_logloss: 0.514719\tvalid's auc: 0.824289\ttrain's binary_logloss: 0.413609\ttrain's auc: 0.909418\n",
      "      fold     train     valid\n",
      "0        0  0.918791  0.836515\n",
      "1        1  0.949656  0.824219\n",
      "2        2  0.925183  0.837162\n",
      "3        3  0.909418  0.824289\n",
      "4  overall  0.925762  0.829930\n",
      "=========\n",
      "RUN IS 18\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid's binary_logloss: 0.514808\tvalid's auc: 0.826799\ttrain's binary_logloss: 0.483115\ttrain's auc: 0.858192\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid's binary_logloss: 0.531131\tvalid's auc: 0.81179\ttrain's binary_logloss: 0.427492\ttrain's auc: 0.888299\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid's binary_logloss: 0.519857\tvalid's auc: 0.82272\ttrain's binary_logloss: 0.467646\ttrain's auc: 0.86415\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid's binary_logloss: 0.536777\tvalid's auc: 0.809655\ttrain's binary_logloss: 0.472274\ttrain's auc: 0.863974\n",
      "      fold     train     valid\n",
      "0        0  0.858192  0.826799\n",
      "1        1  0.888299  0.811790\n",
      "2        2  0.864150  0.822720\n",
      "3        3  0.863974  0.809655\n",
      "4  overall  0.868654  0.816485\n",
      "=========\n",
      "RUN IS 19\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's binary_logloss: 0.546155\tvalid's auc: 0.80913\ttrain's binary_logloss: 0.49805\ttrain's auc: 0.87721\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's binary_logloss: 0.553137\tvalid's auc: 0.79006\ttrain's binary_logloss: 0.451808\ttrain's auc: 0.879435\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's binary_logloss: 0.541994\tvalid's auc: 0.801646\ttrain's binary_logloss: 0.482846\ttrain's auc: 0.871095\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's binary_logloss: 0.544361\tvalid's auc: 0.803281\ttrain's binary_logloss: 0.463513\ttrain's auc: 0.876297\n",
      "      fold     train     valid\n",
      "0        0  0.877210  0.809130\n",
      "1        1  0.879435  0.790060\n",
      "2        2  0.871095  0.801646\n",
      "3        3  0.876297  0.803281\n",
      "4  overall  0.876009  0.795687\n",
      "=========\n",
      "RUN IS 20\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's binary_logloss: 0.524416\tvalid's auc: 0.812518\ttrain's binary_logloss: 0.431332\ttrain's auc: 0.89667\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's binary_logloss: 0.538211\tvalid's auc: 0.801472\ttrain's binary_logloss: 0.373405\ttrain's auc: 0.927439\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's binary_logloss: 0.534493\tvalid's auc: 0.804083\ttrain's binary_logloss: 0.391981\ttrain's auc: 0.917576\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's binary_logloss: 0.534668\tvalid's auc: 0.804263\ttrain's binary_logloss: 0.428116\ttrain's auc: 0.898764\n",
      "      fold     train     valid\n",
      "0        0  0.896670  0.812518\n",
      "1        1  0.927439  0.801472\n",
      "2        2  0.917576  0.804083\n",
      "3        3  0.898764  0.804263\n",
      "4  overall  0.910112  0.804726\n",
      "=========\n",
      "RUN IS 21\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[41]\tvalid's binary_logloss: 0.496292\tvalid's auc: 0.836695\ttrain's binary_logloss: 0.422496\ttrain's auc: 0.901462\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[89]\tvalid's binary_logloss: 0.5066\tvalid's auc: 0.82386\ttrain's binary_logloss: 0.391124\ttrain's auc: 0.92485\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tvalid's binary_logloss: 0.49859\tvalid's auc: 0.83455\ttrain's binary_logloss: 0.395014\ttrain's auc: 0.922878\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[57]\tvalid's binary_logloss: 0.513914\tvalid's auc: 0.824772\ttrain's binary_logloss: 0.404535\ttrain's auc: 0.91384\n",
      "      fold     train     valid\n",
      "0        0  0.901462  0.836695\n",
      "1        1  0.924850  0.823860\n",
      "2        2  0.922878  0.834550\n",
      "3        3  0.913840  0.824772\n",
      "4  overall  0.915758  0.828226\n",
      "=========\n",
      "RUN IS 22\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.524737\tvalid's auc: 0.817318\ttrain's binary_logloss: 0.462721\ttrain's auc: 0.884272\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid's binary_logloss: 0.526944\tvalid's auc: 0.818691\ttrain's binary_logloss: 0.470316\ttrain's auc: 0.881345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid's binary_logloss: 0.578546\tvalid's auc: 0.797527\ttrain's binary_logloss: 0.552091\ttrain's auc: 0.853097\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.513458\tvalid's auc: 0.818544\ttrain's binary_logloss: 0.46748\ttrain's auc: 0.877601\n",
      "Early stopping, best iteration is:\n",
      "[620]\tvalid's binary_logloss: 0.505285\tvalid's auc: 0.821482\ttrain's binary_logloss: 0.449992\ttrain's auc: 0.88353\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.533509\tvalid's auc: 0.805243\ttrain's binary_logloss: 0.472442\ttrain's auc: 0.881103\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid's binary_logloss: 0.531834\tvalid's auc: 0.810333\ttrain's binary_logloss: 0.479959\ttrain's auc: 0.875636\n",
      "      fold     train     valid\n",
      "0        0  0.881345  0.818691\n",
      "1        1  0.853097  0.797527\n",
      "2        2  0.883530  0.821482\n",
      "3        3  0.875636  0.810333\n",
      "4  overall  0.873402  0.779032\n",
      "=========\n",
      "RUN IS 23\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.490028\tvalid's auc: 0.836678\ttrain's binary_logloss: 0.379484\ttrain's auc: 0.921613\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid's binary_logloss: 0.490358\tvalid's auc: 0.837846\ttrain's binary_logloss: 0.408851\ttrain's auc: 0.902966\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.495857\tvalid's auc: 0.827515\ttrain's binary_logloss: 0.376834\ttrain's auc: 0.922632\n",
      "Early stopping, best iteration is:\n",
      "[638]\tvalid's binary_logloss: 0.494325\tvalid's auc: 0.828883\ttrain's binary_logloss: 0.353376\ttrain's auc: 0.936177\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.484055\tvalid's auc: 0.835071\ttrain's binary_logloss: 0.38268\ttrain's auc: 0.920593\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid's binary_logloss: 0.4831\tvalid's auc: 0.836544\ttrain's binary_logloss: 0.404579\ttrain's auc: 0.906677\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[500]\tvalid's binary_logloss: 0.504335\tvalid's auc: 0.822211\ttrain's binary_logloss: 0.375204\ttrain's auc: 0.923912\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid's binary_logloss: 0.503247\tvalid's auc: 0.822753\ttrain's binary_logloss: 0.399976\ttrain's auc: 0.908258\n",
      "      fold     train     valid\n",
      "0        0  0.902966  0.837846\n",
      "1        1  0.936177  0.828883\n",
      "2        2  0.906677  0.836544\n",
      "3        3  0.908258  0.822753\n",
      "4  overall  0.913520  0.830842\n",
      "=========\n",
      "RUN IS 24\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid's binary_logloss: 0.503375\tvalid's auc: 0.827841\ttrain's binary_logloss: 0.415083\ttrain's auc: 0.890525\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid's binary_logloss: 0.510779\tvalid's auc: 0.814957\ttrain's binary_logloss: 0.420397\ttrain's auc: 0.887579\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid's binary_logloss: 0.493308\tvalid's auc: 0.826903\ttrain's binary_logloss: 0.42846\ttrain's auc: 0.883701\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid's binary_logloss: 0.509452\tvalid's auc: 0.815713\ttrain's binary_logloss: 0.442361\ttrain's auc: 0.876503\n",
      "      fold     train     valid\n",
      "0        0  0.890525  0.827841\n",
      "1        1  0.887579  0.814957\n",
      "2        2  0.883701  0.826903\n",
      "3        3  0.876503  0.815713\n",
      "4  overall  0.884577  0.820784\n",
      "=========\n",
      "RUN IS 25\n",
      "=========\n",
      "LGB starting\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid's binary_logloss: 0.513077\tvalid's auc: 0.818147\ttrain's binary_logloss: 0.431729\ttrain's auc: 0.880946\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid's binary_logloss: 0.519454\tvalid's auc: 0.808524\ttrain's binary_logloss: 0.432912\ttrain's auc: 0.879826\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's binary_logloss: 0.507003\tvalid's auc: 0.816686\ttrain's binary_logloss: 0.461846\ttrain's auc: 0.863947\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's binary_logloss: 0.517904\tvalid's auc: 0.809415\ttrain's binary_logloss: 0.450928\ttrain's auc: 0.871455\n",
      "      fold     train     valid\n",
      "0        0  0.880946  0.818147\n",
      "1        1  0.879826  0.808524\n",
      "2        2  0.863947  0.816686\n",
      "3        3  0.871455  0.809415\n",
      "4  overall  0.874044  0.812523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>min_split_gain</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>training_score</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dart</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0519184</td>\n",
       "      <td>60000</td>\n",
       "      <td>58</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.877673</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>True</td>\n",
       "      <td>0.306816</td>\n",
       "      <td>3100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 65, '...</td>\n",
       "      <td>0.990635</td>\n",
       "      <td>0.832303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dart</td>\n",
       "      <td>103</td>\n",
       "      <td>0.102837</td>\n",
       "      <td>80000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>True</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>16100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 103, ...</td>\n",
       "      <td>0.964962</td>\n",
       "      <td>0.831029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dart</td>\n",
       "      <td>108</td>\n",
       "      <td>0.19449</td>\n",
       "      <td>280000</td>\n",
       "      <td>64</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.490306</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>False</td>\n",
       "      <td>0.898061</td>\n",
       "      <td>14100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 108, ...</td>\n",
       "      <td>0.983422</td>\n",
       "      <td>0.830866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dart</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0824694</td>\n",
       "      <td>180000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082551</td>\n",
       "      <td>15100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 55, '...</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>0.830845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goss</td>\n",
       "      <td>91</td>\n",
       "      <td>0.031551</td>\n",
       "      <td>20000</td>\n",
       "      <td>91</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.204878</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.714571</td>\n",
       "      <td>18100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 91, '...</td>\n",
       "      <td>0.91352</td>\n",
       "      <td>0.830842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>104</td>\n",
       "      <td>0.102837</td>\n",
       "      <td>60000</td>\n",
       "      <td>175</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0417755</td>\n",
       "      <td>12100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 104, ...</td>\n",
       "      <td>0.925762</td>\n",
       "      <td>0.82993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dart</td>\n",
       "      <td>23</td>\n",
       "      <td>0.265776</td>\n",
       "      <td>240000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.327204</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734959</td>\n",
       "      <td>100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 23, '...</td>\n",
       "      <td>0.915758</td>\n",
       "      <td>0.828226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dart</td>\n",
       "      <td>52</td>\n",
       "      <td>0.245408</td>\n",
       "      <td>100000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>0.18449</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0417755</td>\n",
       "      <td>19100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 52, '...</td>\n",
       "      <td>0.994423</td>\n",
       "      <td>0.825957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dart</td>\n",
       "      <td>120</td>\n",
       "      <td>0.326878</td>\n",
       "      <td>180000</td>\n",
       "      <td>181</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.877673</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>False</td>\n",
       "      <td>0.63302</td>\n",
       "      <td>2100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 120, ...</td>\n",
       "      <td>0.965113</td>\n",
       "      <td>0.82186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>39</td>\n",
       "      <td>0.38798</td>\n",
       "      <td>220000</td>\n",
       "      <td>154</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.286429</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>True</td>\n",
       "      <td>0.449531</td>\n",
       "      <td>7100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 39, '...</td>\n",
       "      <td>0.895957</td>\n",
       "      <td>0.821649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>goss</td>\n",
       "      <td>67</td>\n",
       "      <td>0.163939</td>\n",
       "      <td>220000</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.959224</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>False</td>\n",
       "      <td>0.81651</td>\n",
       "      <td>13100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 67, '...</td>\n",
       "      <td>0.884577</td>\n",
       "      <td>0.820784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>goss</td>\n",
       "      <td>39</td>\n",
       "      <td>0.204673</td>\n",
       "      <td>180000</td>\n",
       "      <td>196</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.0204082</td>\n",
       "      <td>0.388367</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>True</td>\n",
       "      <td>0.327204</td>\n",
       "      <td>7100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 39, '...</td>\n",
       "      <td>0.864478</td>\n",
       "      <td>0.82053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>29</td>\n",
       "      <td>0.357429</td>\n",
       "      <td>60000</td>\n",
       "      <td>49</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>0.551469</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>True</td>\n",
       "      <td>0.714571</td>\n",
       "      <td>3100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 29, '...</td>\n",
       "      <td>0.900408</td>\n",
       "      <td>0.819453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>goss</td>\n",
       "      <td>88</td>\n",
       "      <td>0.275959</td>\n",
       "      <td>140000</td>\n",
       "      <td>133</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.959224</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>True</td>\n",
       "      <td>0.877673</td>\n",
       "      <td>5100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 88, '...</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>0.816908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>goss</td>\n",
       "      <td>146</td>\n",
       "      <td>0.214857</td>\n",
       "      <td>220000</td>\n",
       "      <td>106</td>\n",
       "      <td>0.22449</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.408755</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959224</td>\n",
       "      <td>13100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 146, ...</td>\n",
       "      <td>0.868654</td>\n",
       "      <td>0.816485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dart</td>\n",
       "      <td>134</td>\n",
       "      <td>0.245408</td>\n",
       "      <td>220000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0612245</td>\n",
       "      <td>0.44898</td>\n",
       "      <td>0.551469</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449531</td>\n",
       "      <td>12100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 134, ...</td>\n",
       "      <td>0.994557</td>\n",
       "      <td>0.815258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>goss</td>\n",
       "      <td>48</td>\n",
       "      <td>0.245408</td>\n",
       "      <td>140000</td>\n",
       "      <td>67</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571857</td>\n",
       "      <td>8100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 48, '...</td>\n",
       "      <td>0.874044</td>\n",
       "      <td>0.812523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>17</td>\n",
       "      <td>0.255592</td>\n",
       "      <td>20000</td>\n",
       "      <td>70</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.0417755</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>False</td>\n",
       "      <td>0.469918</td>\n",
       "      <td>2100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 17, '...</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.812516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>goss</td>\n",
       "      <td>129</td>\n",
       "      <td>0.275959</td>\n",
       "      <td>220000</td>\n",
       "      <td>115</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>0.714571</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>True</td>\n",
       "      <td>0.388367</td>\n",
       "      <td>11100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 129, ...</td>\n",
       "      <td>0.858009</td>\n",
       "      <td>0.811406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>76</td>\n",
       "      <td>0.408347</td>\n",
       "      <td>40000</td>\n",
       "      <td>67</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.714571</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>True</td>\n",
       "      <td>0.755347</td>\n",
       "      <td>4100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 76, '...</td>\n",
       "      <td>0.916538</td>\n",
       "      <td>0.808583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>73</td>\n",
       "      <td>0.469449</td>\n",
       "      <td>240000</td>\n",
       "      <td>58</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.877673</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>True</td>\n",
       "      <td>0.225265</td>\n",
       "      <td>14100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 73, '...</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.804726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>goss</td>\n",
       "      <td>17</td>\n",
       "      <td>0.377796</td>\n",
       "      <td>280000</td>\n",
       "      <td>70</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0621633</td>\n",
       "      <td>17100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 17, '...</td>\n",
       "      <td>0.836287</td>\n",
       "      <td>0.801716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>95</td>\n",
       "      <td>0.0111837</td>\n",
       "      <td>200000</td>\n",
       "      <td>157</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.0213878</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>True</td>\n",
       "      <td>0.796122</td>\n",
       "      <td>5100</td>\n",
       "      <td>[{'boosting_type': 'gbdt', 'num_leaves': 95, '...</td>\n",
       "      <td>0.825389</td>\n",
       "      <td>0.798609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>goss</td>\n",
       "      <td>148</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>140000</td>\n",
       "      <td>52</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.673796</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>True</td>\n",
       "      <td>0.164102</td>\n",
       "      <td>7100</td>\n",
       "      <td>[{'boosting_type': 'goss', 'num_leaves': 148, ...</td>\n",
       "      <td>0.876009</td>\n",
       "      <td>0.795687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dart</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0722857</td>\n",
       "      <td>240000</td>\n",
       "      <td>154</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.0621633</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>5100</td>\n",
       "      <td>[{'boosting_type': 'dart', 'num_leaves': 35, '...</td>\n",
       "      <td>0.873402</td>\n",
       "      <td>0.779032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boosting_type num_leaves learning_rate subsample_for_bin min_data_in_leaf  \\\n",
       "0           dart         65     0.0519184             60000               58   \n",
       "1           dart        103      0.102837             80000               88   \n",
       "2           dart        108       0.19449            280000               64   \n",
       "3           dart         55     0.0824694            180000               10   \n",
       "4           goss         91      0.031551             20000               91   \n",
       "5           gbdt        104      0.102837             60000              175   \n",
       "6           dart         23      0.265776            240000              118   \n",
       "7           dart         52      0.245408            100000               13   \n",
       "8           dart        120      0.326878            180000              181   \n",
       "9           gbdt         39       0.38798            220000              154   \n",
       "10          goss         67      0.163939            220000              106   \n",
       "11          goss         39      0.204673            180000              196   \n",
       "12          gbdt         29      0.357429             60000               49   \n",
       "13          goss         88      0.275959            140000              133   \n",
       "14          goss        146      0.214857            220000              106   \n",
       "15          dart        134      0.245408            220000               40   \n",
       "16          goss         48      0.245408            140000               67   \n",
       "17          gbdt         17      0.255592             20000               70   \n",
       "18          goss        129      0.275959            220000              115   \n",
       "19          gbdt         76      0.408347             40000               67   \n",
       "20          gbdt         73      0.469449            240000               58   \n",
       "21          goss         17      0.377796            280000               70   \n",
       "22          gbdt         95     0.0111837            200000              157   \n",
       "23          goss        148      0.316694            140000               52   \n",
       "24          dart         35     0.0722857            240000              154   \n",
       "\n",
       "    reg_alpha reg_lambda colsample_bytree subsample is_unbalance  \\\n",
       "0    0.591837   0.959184         0.877673  0.540816         True   \n",
       "1   0.0204082   0.612245         0.266041  0.632653         True   \n",
       "2    0.734694   0.816327         0.490306  0.795918        False   \n",
       "3    0.571429          0         0.857286  0.897959        False   \n",
       "4    0.897959   0.755102         0.204878       0.5        False   \n",
       "5    0.632653   0.653061         0.347592  0.867347         True   \n",
       "6    0.938776   0.428571         0.327204  0.989796         True   \n",
       "7    0.959184  0.0612245          0.18449  0.581633        False   \n",
       "8    0.408163   0.469388         0.877673  0.918367        False   \n",
       "9    0.428571   0.979592         0.286429  0.806122         True   \n",
       "10          1   0.142857         0.959224  0.908163        False   \n",
       "11   0.265306  0.0204082         0.388367  0.928571         True   \n",
       "12   0.469388  0.0612245         0.551469  0.755102         True   \n",
       "13   0.142857   0.795918         0.959224  0.683673         True   \n",
       "14    0.22449   0.653061         0.408755  0.653061         True   \n",
       "15  0.0612245    0.44898         0.551469  0.857143        False   \n",
       "16   0.979592   0.959184         0.857286  0.979592        False   \n",
       "17   0.612245   0.897959        0.0417755  0.622449        False   \n",
       "18   0.632653  0.0816327         0.714571  0.826531         True   \n",
       "19   0.591837   0.530612         0.714571  0.816327         True   \n",
       "20   0.693878   0.632653         0.877673  0.591837         True   \n",
       "21   0.734694   0.734694                1  0.897959         True   \n",
       "22   0.632653   0.387755        0.0213878   0.77551         True   \n",
       "23   0.306122   0.612245         0.673796  0.989796         True   \n",
       "24   0.897959   0.367347        0.0621633         1        False   \n",
       "\n",
       "   min_split_gain n_estimators  \\\n",
       "0        0.306816         3100   \n",
       "1        0.164102        16100   \n",
       "2        0.898061        14100   \n",
       "3        0.082551        15100   \n",
       "4        0.714571        18100   \n",
       "5       0.0417755        12100   \n",
       "6        0.734959          100   \n",
       "7       0.0417755        19100   \n",
       "8         0.63302         2100   \n",
       "9        0.449531         7100   \n",
       "10        0.81651        13100   \n",
       "11       0.327204         7100   \n",
       "12       0.714571         3100   \n",
       "13       0.877673         5100   \n",
       "14       0.959224        13100   \n",
       "15       0.449531        12100   \n",
       "16       0.571857         8100   \n",
       "17       0.469918         2100   \n",
       "18       0.388367        11100   \n",
       "19       0.755347         4100   \n",
       "20       0.225265        14100   \n",
       "21      0.0621633        17100   \n",
       "22       0.796122         5100   \n",
       "23       0.164102         7100   \n",
       "24       0.245653         5100   \n",
       "\n",
       "                                               params training_score  \\\n",
       "0   [{'boosting_type': 'dart', 'num_leaves': 65, '...       0.990635   \n",
       "1   [{'boosting_type': 'dart', 'num_leaves': 103, ...       0.964962   \n",
       "2   [{'boosting_type': 'dart', 'num_leaves': 108, ...       0.983422   \n",
       "3   [{'boosting_type': 'dart', 'num_leaves': 55, '...       0.992971   \n",
       "4   [{'boosting_type': 'goss', 'num_leaves': 91, '...        0.91352   \n",
       "5   [{'boosting_type': 'gbdt', 'num_leaves': 104, ...       0.925762   \n",
       "6   [{'boosting_type': 'dart', 'num_leaves': 23, '...       0.915758   \n",
       "7   [{'boosting_type': 'dart', 'num_leaves': 52, '...       0.994423   \n",
       "8   [{'boosting_type': 'dart', 'num_leaves': 120, ...       0.965113   \n",
       "9   [{'boosting_type': 'gbdt', 'num_leaves': 39, '...       0.895957   \n",
       "10  [{'boosting_type': 'goss', 'num_leaves': 67, '...       0.884577   \n",
       "11  [{'boosting_type': 'goss', 'num_leaves': 39, '...       0.864478   \n",
       "12  [{'boosting_type': 'gbdt', 'num_leaves': 29, '...       0.900408   \n",
       "13  [{'boosting_type': 'goss', 'num_leaves': 88, '...        0.85764   \n",
       "14  [{'boosting_type': 'goss', 'num_leaves': 146, ...       0.868654   \n",
       "15  [{'boosting_type': 'dart', 'num_leaves': 134, ...       0.994557   \n",
       "16  [{'boosting_type': 'goss', 'num_leaves': 48, '...       0.874044   \n",
       "17  [{'boosting_type': 'gbdt', 'num_leaves': 17, '...        0.88113   \n",
       "18  [{'boosting_type': 'goss', 'num_leaves': 129, ...       0.858009   \n",
       "19  [{'boosting_type': 'gbdt', 'num_leaves': 76, '...       0.916538   \n",
       "20  [{'boosting_type': 'gbdt', 'num_leaves': 73, '...       0.910112   \n",
       "21  [{'boosting_type': 'goss', 'num_leaves': 17, '...       0.836287   \n",
       "22  [{'boosting_type': 'gbdt', 'num_leaves': 95, '...       0.825389   \n",
       "23  [{'boosting_type': 'goss', 'num_leaves': 148, ...       0.876009   \n",
       "24  [{'boosting_type': 'dart', 'num_leaves': 35, '...       0.873402   \n",
       "\n",
       "   valid_score  \n",
       "0     0.832303  \n",
       "1     0.831029  \n",
       "2     0.830866  \n",
       "3     0.830845  \n",
       "4     0.830842  \n",
       "5      0.82993  \n",
       "6     0.828226  \n",
       "7     0.825957  \n",
       "8      0.82186  \n",
       "9     0.821649  \n",
       "10    0.820784  \n",
       "11     0.82053  \n",
       "12    0.819453  \n",
       "13    0.816908  \n",
       "14    0.816485  \n",
       "15    0.815258  \n",
       "16    0.812523  \n",
       "17    0.812516  \n",
       "18    0.811406  \n",
       "19    0.808583  \n",
       "20    0.804726  \n",
       "21    0.801716  \n",
       "22    0.798609  \n",
       "23    0.795687  \n",
       "24    0.779032  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df = tune_lgb(X_train, y_train, param_grid, runs=25)\n",
    "runs_df = runs_df.sort_values(by='valid_score', ascending=False).reset_index(drop=True)\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'num_leaves': 65,\n",
       " 'learning_rate': 0.051918367346938776,\n",
       " 'subsample_for_bin': 60000,\n",
       " 'min_data_in_leaf': 58,\n",
       " 'reg_alpha': 0.5918367346938775,\n",
       " 'reg_lambda': 0.9591836734693877,\n",
       " 'colsample_bytree': 0.8776734693877551,\n",
       " 'subsample': 0.5408163265306123,\n",
       " 'is_unbalance': True,\n",
       " 'min_split_gain': 0.30681632653061225,\n",
       " 'n_estimators': 3100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params=runs_df.loc[0, 'params'][0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.9997703372347809\n",
      "Test 0.8271189231879423\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = lgb.LGBMClassifier(**best_params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, eval_metric = 'auc', verbose=500)\n",
    "\n",
    "# Record the best iteration\n",
    "best_iteration = model.best_iteration_\n",
    "\n",
    "# Record feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Record the out of fold predictions\n",
    "train_predict = model.predict_proba(X_train, num_iteration = best_iteration)\n",
    "test_predict = model.predict_proba(X_test, num_iteration = best_iteration)\n",
    "\n",
    "# Get AUC\n",
    "train_score = roc_auc_score(y_train, train_predict[:,1])\n",
    "test_score = roc_auc_score(y_test, test_predict[:,1])\n",
    "\n",
    "print('Train', train_score)\n",
    "print('Test', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BUN</td>\n",
       "      <td>7494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Phosphorus</td>\n",
       "      <td>7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PTT</td>\n",
       "      <td>7256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Creatinine</td>\n",
       "      <td>6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RDW</td>\n",
       "      <td>6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>White blood cells</td>\n",
       "      <td>6745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admission weight</td>\n",
       "      <td>6741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Platelet Count</td>\n",
       "      <td>6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lymphocytes</td>\n",
       "      <td>6681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Neutrophils</td>\n",
       "      <td>6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Red Blood Cells</td>\n",
       "      <td>6151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BP diastolic</td>\n",
       "      <td>5675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Temperature F</td>\n",
       "      <td>5639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hematocrit</td>\n",
       "      <td>5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Monocytes</td>\n",
       "      <td>5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Urea Nitrogen</td>\n",
       "      <td>5413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Eosinophils</td>\n",
       "      <td>5348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BP systolic</td>\n",
       "      <td>5257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MCHC</td>\n",
       "      <td>5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HR</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MCH</td>\n",
       "      <td>4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP mean</td>\n",
       "      <td>4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pH</td>\n",
       "      <td>3825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Calcium (Total)</td>\n",
       "      <td>3782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hemoglobin</td>\n",
       "      <td>3757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chloride</td>\n",
       "      <td>3677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Potassium</td>\n",
       "      <td>3595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Magnesium</td>\n",
       "      <td>3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Respiratory rate</td>\n",
       "      <td>2752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MCV</td>\n",
       "      <td>2343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sodium</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Basophils</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>age_adm_bucket_4. 75-89</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>age_adm_bucket_2. 45-60</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>age_adm_bucket_5. 89</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>age_adm_bucket_1. &lt;45</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gender_F</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gender_M</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>age_adm_bucket_3. 60-75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "12                  Glucose        7760\n",
       "5                       BUN        7494\n",
       "24               Phosphorus        7293\n",
       "23                      PTT        7256\n",
       "10               Creatinine        6982\n",
       "27                      RDW        6850\n",
       "33        White blood cells        6745\n",
       "0          Admission weight        6741\n",
       "25           Platelet Count        6724\n",
       "16              Lymphocytes        6681\n",
       "22              Neutrophils        6405\n",
       "28          Red Blood Cells        6151\n",
       "2              BP diastolic        5675\n",
       "31            Temperature F        5639\n",
       "14               Hematocrit        5498\n",
       "21                Monocytes        5455\n",
       "32            Urea Nitrogen        5413\n",
       "11              Eosinophils        5348\n",
       "4               BP systolic        5257\n",
       "18                     MCHC        5123\n",
       "13                       HR        4918\n",
       "17                      MCH        4554\n",
       "3                   BP mean        4398\n",
       "34                       pH        3825\n",
       "8           Calcium (Total)        3782\n",
       "15               Hemoglobin        3757\n",
       "9                  Chloride        3677\n",
       "26                Potassium        3595\n",
       "20                Magnesium        3025\n",
       "29         Respiratory rate        2752\n",
       "7               Bicarbonate        2537\n",
       "19                      MCV        2343\n",
       "30                   Sodium        2099\n",
       "6                 Basophils        1945\n",
       "1                 Anion Gap        1497\n",
       "38  age_adm_bucket_4. 75-89         828\n",
       "36  age_adm_bucket_2. 45-60         683\n",
       "39     age_adm_bucket_5. 89         573\n",
       "35    age_adm_bucket_1. <45         441\n",
       "40                 gender_F         282\n",
       "41                 gender_M          41\n",
       "37  age_adm_bucket_3. 60-75           4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = pd.DataFrame({'feature': feature_names,\n",
    "                                       'importance': feature_importances})\n",
    "feature_importances_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feature_importances_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mimic]",
   "language": "python",
   "name": "conda-env-mimic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
