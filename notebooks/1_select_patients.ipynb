{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MUST DELETE\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths & import functions\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src_folder = os.path.join(project_root, 'src')\n",
    "sys.path.insert(0, src_folder)\n",
    "from stats_and_visualisations import *\n",
    "from patient_selection import *\n",
    "from utilities import *\n",
    "from modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- OPTIONS\n",
    "optional_exclusions = ['first_diagnosis_only', 'exclude_newborns', 'exclude_deaths']\n",
    "match_on = ['age_adm_bucket', 'gender']\n",
    "profile_data = ['age_adm_bucket', 'gender']\n",
    "show_graphs = True\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_patients_and_select_chartevents(diagnosis_id, diagnosis_name,\n",
    "                                           test_size=0.33,\n",
    "                                           optional_exclusions=None,\n",
    "                                           profile_data=None,\n",
    "                                           match_on=False,\n",
    "                                           show_graphs=False):\n",
    "    \n",
    "    '''\n",
    "\n",
    "    Function that for a given dignosis idc9 code:\n",
    "        1) Finds patients who were diagnosed with the condition (target=1) and a 'base' group who were never diagnosed\n",
    "           with the condition (target=0)\n",
    "        2) Adds the final chart and lab events for each admission, and (optionally) additional patient demographic\n",
    "           data such as gender and age. It also optionally provides visualisations of the chart, lab and demographic\n",
    "           data so that comparisons can be seen between the subject and base groups\n",
    "        3) Finally, it splits the data into a training set and a test set, both of which are saved on AWS S3\n",
    "    \n",
    "    The arguments are as follows:\n",
    "        1) diagnosis_id: the icd9 code of the diagnosis that we wish to find patients for, with an appropriate base\n",
    "           group who never had the diagnosis.\n",
    "        2) diagnosis_name: the corresponding name for the diagnosis_id. Used to name the output training and test\n",
    "           sets, so can be in short form/ easy to understand language.\n",
    "        3) test_size: the proportion of total patients that should be placed in the test dataset (between 0 and 1).\n",
    "           The default is 0.33.\n",
    "        4) optional_exclusions: There are additional optional exlusions that can be applied to the subject and\n",
    "           base group. These should be passed as a list into the optional_exclusions argument. This argument can\n",
    "           be omitted if no exclusions are needed:\n",
    "              a) first_diagnosis_only - this means that only one admission per patient\n",
    "                 will be included in the output dataframes. In the subject dataframe,\n",
    "                 the first admission where they were diagnosed with the condition will\n",
    "                 be included (not necessarily their first admission overall, if they \n",
    "                 were not diagnosed on their first admission)\n",
    "              b) exclude_newborns - excludes all admissions with admission_type ==\n",
    "                 'NEWBORN'\n",
    "              c) exclude_deaths - excludes all admissions that resulted in the\n",
    "                 patient dying\n",
    "        5) profile_data: the patient demographic data that is required in the final datasets. Needs to be passed\n",
    "           as a list, eg ['gender', 'age_adm_bucket']. Must be a column in the admission_diagnosis_table dataset.\n",
    "        6) match_on: The subject and base groups can be matched on their patient demographic data with the match_on\n",
    "           argument. The match can take place on any demographic data in the input dataframe, and the chosen columns\n",
    "           for the match should be passed as a list, eg ['gender', 'ethnicity_simple'].\n",
    "           \n",
    "           The match works by randomly sampling the base group so the proportions in each demographic bucket match\n",
    "           the proportions in the subject group. For example, if the proportion of males to females in the\n",
    "           subject group is 60/40 whereas in the base group it is 50/50, then the base group will be randomly\n",
    "           sampled so that the male to female ratio is also 60/40.\n",
    "           \n",
    "           The match is taken on all combinations of matched columns together rather than separately. Eg, if 10% of\n",
    "           the sampled group is white female, then the base group will be sampled so that 10% are also white female,\n",
    "           rather than sampling ethnicity and gender separately. Therefore, it's recommended to only match on groups\n",
    "           where there are large volumes in each bucket, otherwise the base group could become quite small\n",
    "           \n",
    "        7) show_graphs: if True, graphs are output which show comparisons between the subject and base groups\n",
    "           for chart, lab and demographic data\n",
    "\n",
    "    '''\n",
    "    \n",
    "    df = select_test_groups(diagnosis_id, optional_exclusions=optional_exclusions,\n",
    "                            match_on=match_on, show_graphs=show_graphs)\n",
    "                            \n",
    "    df = add_chart_data(df)\n",
    "\n",
    "    if profile_data:\n",
    "        df = add_profile_data(df, profile_data=profile_data)\n",
    "        non_chart_cols = ['subject_id', 'hadm_id', 'target'] +  profile_data\n",
    "    else:\n",
    "        non_chart_cols = ['subject_id', 'hadm_id', 'target']\n",
    "    \n",
    "    if show_graphs:\n",
    "        # Plot a KDE for all remaining cols\n",
    "        cols = [c for c in df.columns if c not in non_chart_cols]\n",
    "        for c in cols:\n",
    "            plot_KDE(df, 'target', 1, 0, c)\n",
    "            \n",
    "    # Create dummy variables for categorical variables so that ML models can be used\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Shuffle and reset index so that the subject and base groups are mixed together\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    # Take test and train splits\n",
    "    train, test = train_test_split(df, test_size=test_size, shuffle=True, random_state=8)\n",
    "    \n",
    "    print(\"--> Training set counts: \",\"\\n\",train.target.value_counts())\n",
    "    print(\"--> Test set counts: \",\"\\n\",test.target.value_counts())\n",
    "    \n",
    "    # Do final cleaning\n",
    "    X_train, X_test, y_train, y_test, feature_names = final_cleaning(ids = ['subject_id', 'hadm_id'],\n",
    "                                                                     target ='target', train=train, test=test)\n",
    "    \n",
    "    # Export to csv\n",
    "    to_s3(obj=X_train, bucket='mimic-jamesi', filename='{}_X_train.npy'.format(diagnosis_name))\n",
    "    to_s3(obj=X_test, bucket='mimic-jamesi', filename='{}_X_test.npy'.format(diagnosis_name))\n",
    "    to_s3(obj=y_train, bucket='mimic-jamesi', filename='{}_y_train.npy'.format(diagnosis_name))\n",
    "    to_s3(obj=y_test, bucket='mimic-jamesi', filename='{}_y_test.npy'.format(diagnosis_name))\n",
    "    to_s3(obj=feature_names, bucket='mimic-jamesi', filename='{}_feature_names.npy'.format(diagnosis_name))\n",
    "    \n",
    "    del df, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_test_groups(diagnosis,\n",
    "                       optional_exclusions=None,\n",
    "                       match_on=False,\n",
    "                       show_graphs=False):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    For a given diagnoses icd9 code, returns a single dataframe showing patients and admissions that either did or\n",
    "    didn't have the disgnosis (denoted by target == 1 or 0) \n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Find initial subject and base group for the given diagnosis\n",
    "    subject_adm, base_adm = get_diagnosis_groups(diagnosis, optional_exclusions=optional_exclusions)\n",
    "    \n",
    "    if match_on:\n",
    "        base_adm = take_match_control(subject_adm, base_adm, match_on=match_on)\n",
    "\n",
    "    # Combine into a single DF\n",
    "    subject_adm['target'] = 1\n",
    "    base_adm['target'] = 0\n",
    "    df = subject_adm.append(base_adm).reset_index(drop=True)\n",
    "\n",
    "    if show_graphs:\n",
    "        graph_comparisons(df = df, ids = 'hadm_id', group_col = 'target', group_a = 1, group_b = 0)\n",
    "\n",
    "    df['subject_id'] = df['subject_id'].astype(int)\n",
    "    df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "    \n",
    "    df = df[['subject_id', 'hadm_id', 'target']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_match_control(subject_adm, base_adm, match_on):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    For a given subject and base group, returns a new base group that is identical in proportions for\n",
    "    given variables compared to the subject group.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # === 1 === For the subject and base groups, calculate the proportion of patients in each combination of the\n",
    "    #           match_on variables. This is so the proportions can be compared, and ultimately the base group can\n",
    "    #           be sampled until it's proportions are equal to the subject proportions\n",
    "    \n",
    "    # Subjects\n",
    "    subject_segments = (subject_adm.groupby(match_on)\n",
    "                                   .agg({'hadm_id':'nunique'})\n",
    "                                   .rename(columns={'hadm_id':'subjects_n'})\n",
    "                                   .reset_index())\n",
    "    subject_segments['subjects_prop'] = subject_segments['subjects_n'] / subject_segments['subjects_n'].sum()\n",
    "\n",
    "    # Base\n",
    "    base_segments = (base_adm.groupby(match_on)\n",
    "                             .agg({'hadm_id':'nunique'})\n",
    "                             .rename(columns={'hadm_id':'base_n'})\n",
    "                             .reset_index())\n",
    "    base_segments['base_prop'] = base_segments['base_n'] / base_segments['base_n'].sum()\n",
    "\n",
    "    proportions_compare = pd.merge(subject_segments, base_segments, how='outer',\n",
    "                                   left_on=match_on, right_on=match_on)\n",
    "\n",
    "    # === 2 === Compare proportions: For each combination, the proportion % of the base and the subject group should\n",
    "    #           be compared. The goal is to find the combination where there is the lowest ratio of base group to\n",
    "    #           subject group. This is because this is the combination group that cannot be down sampled any further\n",
    "    #           if we want to maximise the size of the base group. Therefore, if we know the size of this combination\n",
    "    #           group we can use it as a basis for calculating the target size of all other combination groups\n",
    "    \n",
    "    proportions_compare['ratio'] = proportions_compare['base_prop'] / proportions_compare['subjects_prop']\n",
    "    lowest = proportions_compare[proportions_compare['ratio']==proportions_compare['ratio'].min()]\n",
    "    total_sample_size = math.floor(lowest['base_n'] / lowest['subjects_prop'])\n",
    "    proportions_compare['new_base_grp_size'] = ((total_sample_size * proportions_compare['subjects_prop'])\n",
    "                                                .apply(np.floor))\n",
    "\n",
    "    # === 3 === With the target group size known for each combination, loop through each combination and randomly\n",
    "    #           sample from the base group the desired number of admissions\n",
    "                                \n",
    "    base_adm_sampled = df_empty(columns=base_adm.columns.tolist(), dtypes=base_adm.dtypes.tolist())\n",
    "\n",
    "    for idx,row in proportions_compare.iterrows():\n",
    "        \n",
    "        tmp_base = base_adm.copy()\n",
    "        \n",
    "        n = int(row['new_base_grp_size'])\n",
    "        \n",
    "        for val in match_on:\n",
    "            tmp_base = tmp_base[tmp_base[val]==row[val]]\n",
    "                    \n",
    "        sample_df = tmp_base.sample(n=n, random_state=8)\n",
    "\n",
    "        base_adm_sampled = base_adm_sampled.append(sample_df)\n",
    "        \n",
    "        del sample_df, tmp_base\n",
    "\n",
    "    print('--> Original base group size: ', len(base_adm))\n",
    "    print('--> Sampled base group size: ', len(base_adm_sampled))\n",
    "    print('--> Subject group size: ', len(subject_adm))\n",
    "    \n",
    "    return base_adm_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mimic/src/patient_selection.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  subject_adm.drop(columns=['diagnosis_name', 'diagnosis_icd9'], inplace=True)\n",
      "/home/ubuntu/mimic/src/patient_selection.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  subject_adm.drop_duplicates(inplace=True)\n",
      "/home/ubuntu/mimic/src/patient_selection.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  base_adm.drop(columns=['diagnosis_name', 'diagnosis_icd9'], inplace=True)\n",
      "/home/ubuntu/mimic/src/patient_selection.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  base_adm.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Original base group size:  27967\n",
      "--> Sampled base group size:  9479\n",
      "--> Subject group size:  6096\n",
      "Index(['subject_id', 'hadm_id', 'target', 'Admission weight', 'Anion Gap',\n",
      "       'BP diastolic', 'BP mean', 'BP systolic', 'BUN', 'Basophils',\n",
      "       'Bicarbonate', 'Calcium (Total)', 'Chloride', 'Creatinine',\n",
      "       'Eosinophils', 'Glucose', 'HR', 'Hematocrit', 'Hemoglobin', 'Lactate',\n",
      "       'Lymphocytes', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Monocytes',\n",
      "       'Neutrophils', 'Oxygen saturation', 'PCO2', 'PO2', 'PTT', 'Phosphorus',\n",
      "       'Platelet Count', 'Potassium', 'RDW', 'Red Blood Cells',\n",
      "       'Respiratory rate', 'Sodium', 'Temperature F', 'Urea Nitrogen',\n",
      "       'White blood cells', 'pH', 'age_adm_bucket', 'gender'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'target', 'Admission weight', 'Anion Gap',\n",
      "       'BP diastolic', 'BP mean', 'BP systolic', 'BUN', 'Basophils',\n",
      "       'Bicarbonate', 'Calcium (Total)', 'Chloride', 'Creatinine',\n",
      "       'Eosinophils', 'Glucose', 'HR', 'Hematocrit', 'Hemoglobin', 'Lactate',\n",
      "       'Lymphocytes', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Monocytes',\n",
      "       'Neutrophils', 'Oxygen saturation', 'PCO2', 'PO2', 'PTT', 'Phosphorus',\n",
      "       'Platelet Count', 'Potassium', 'RDW', 'Red Blood Cells',\n",
      "       'Respiratory rate', 'Sodium', 'Temperature F', 'Urea Nitrogen',\n",
      "       'White blood cells', 'pH', 'age_adm_bucket_1. <45',\n",
      "       'age_adm_bucket_2. 45-60', 'age_adm_bucket_3. 60-75',\n",
      "       'age_adm_bucket_4. 75-89', 'age_adm_bucket_5. 89', 'gender_F',\n",
      "       'gender_M'],\n",
      "      dtype='object')\n",
      "--> Training set counts:  \n",
      " 0    7598\n",
      "1    4862\n",
      "Name: target, dtype: int64\n",
      "--> Test set counts:  \n",
      " 0    1881\n",
      "1    1234\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "select_patients_and_select_chartevents('5849', 'acute_kidney_failure',\n",
    "                                       show_graphs=show_graphs,\n",
    "                                       test_size=test_size,\n",
    "                                       match_on=match_on,\n",
    "                                       optional_exclusions=optional_exclusions,\n",
    "                                       profile_data=profile_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_p36)",
   "language": "python",
   "name": "tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
